<!doctype html><html lang=en-us dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Tutorial - An Entry DevOps project | Zirui's Space</title>
<meta name=keywords content="AWS,Cloud"><meta name=description content="A comprehensive guide on hosting AWS website along with CI/CD automation and infrastructure as code..."><meta name=author content="Zirui"><link rel=canonical href=https://www.ziirui-resume-website.com/posts/tech/cloud_website/><link crossorigin=anonymous href=/assets/css/stylesheet.css rel="preload stylesheet" as=style><script defer crossorigin=anonymous src=/assets/js/highlight.js onload=hljs.initHighlightingOnLoad()></script><script defer crossorigin=anonymous src=/js/cursor.min.js></script><link rel=icon href=https://www.ziirui-resume-website.com/img/Q.jpg><link rel=icon type=image/png sizes=16x16 href=https://www.ziirui-resume-website.com/img/Q.jpg><link rel=icon type=image/png sizes=32x32 href=https://www.ziirui-resume-website.com/img/Q.jpg><link rel=apple-touch-icon href=https://www.ziirui-resume-website.com/img/Q.jpgf><link rel=mask-icon href=https://www.ziirui-resume-website.com/img/Q.jpg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en-us href=https://www.ziirui-resume-website.com/posts/tech/cloud_website/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script defer src=https://unpkg.com/mermaid@8.8.1/dist/mermaid.min.js></script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/font-awesome@4.7.0/css/font-awesome.min.css><script src=//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js></script><script src=https://cdn.jsdelivr.net/npm/jquery@3.6.3/dist/jquery.min.js></script><script>var _hmt=_hmt||[];(function(){var e,t=document.createElement("script");t.src="",e=document.getElementsByTagName("script")[0],e.parentNode.insertBefore(t,e)})()</script><link rel=preconnect href=https://fonts.googleapis.com><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link href="https://fonts.googleapis.com/css2?family=Josefin+Sans:ital,wght@0,100..700;1,100..700&display=swap" rel=stylesheet><meta property="og:title" content="Tutorial - An Entry DevOps project"><meta property="og:description" content="A comprehensive guide on hosting AWS website along with CI/CD automation and infrastructure as code..."><meta property="og:type" content="article"><meta property="og:url" content="https://www.ziirui-resume-website.com/posts/tech/cloud_website/"><meta property="og:image" content="https://www.ziirui-resume-website.com/posts/tech/cloud_website/aws_logo.jpg"><meta property="article:section" content="posts"><meta property="article:published_time" content="2024-08-15T00:00:00+00:00"><meta property="article:modified_time" content="2024-08-15T00:00:00+00:00"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://www.ziirui-resume-website.com/posts/tech/cloud_website/aws_logo.jpg"><meta name=twitter:title content="Tutorial - An Entry DevOps project"><meta name=twitter:description content="A comprehensive guide on hosting AWS website along with CI/CD automation and infrastructure as code..."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"üìöPosts","item":"https://www.ziirui-resume-website.com/posts/"},{"@type":"ListItem","position":2,"name":"üë®üèª‚Äçüíª Tech","item":"https://www.ziirui-resume-website.com/posts/tech/"},{"@type":"ListItem","position":3,"name":"Tutorial - An Entry DevOps project","item":"https://www.ziirui-resume-website.com/posts/tech/cloud_website/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Tutorial - An Entry DevOps project","name":"Tutorial - An Entry DevOps project","description":"A comprehensive guide on hosting AWS website along with CI/CD automation and infrastructure as code...","keywords":["AWS","Cloud"],"articleBody":" Introduction This guide is based on the Cloud Resume Challenge and follows the steps listed inside it. That said, I strongly recommend purchasing the original book as it covers much more details. This post will only show the method I‚Äôve done for my challenge. Think of this post as a helpful guide rather than a complete answer key.\nThe elements cover in this post:\nAWS (S3 bucket, Cloudfront, IAM, Lambda Function, DynamoDB, Identity Provider OIDC, DNS, SSL Manager and more) CI/CD (Git Action) infrastructure as code (Terraform) Frontend Language (HTML, CSS) -\u003e Now switch to Hugo Backend Language (Python, Javascript) Test (Cypress) Please read through the on the offical website before looking into my post, because I will directly dive into how I solve the problem. 1. Certification The challenge recommonds the Certified Cloud Practitioner as a basic level. However I passed the Solutions Architect - Associate for a higher level approach. Ultimately the certificate offers professional knowledge regarding cloud services.\nQ\u0026A Q: Is getting a certificate worthy? A: The short answer: yes and no. If you want to become a cloud engineer or similar role (Site reliabilty Engineer, DevOps engineer), the answer is yes! If your goal is just to learn cloud services, then a certificate will not be worthy. Here are 2 major benefits: 1. Experience from the Certificate: The resume challenge will guide you through a limited set of AWS resources, specifically focusing on how to host a static website. Most of the time, you will need to handle various scenarios. Let me offer you some cases: - Are you familiar with VPC networks and EC2 instances, which are commonly used by companies? - How to prevent accidental deletion in bucket? (Versioning / MFA) - Do you understand the architectural difference between a company that wants to migrate services from on-premise to the cloud while treating the on-premise data center as a backup, versus a company that wants to extend its data storage to the cloud but keep all services hosted on-premises? - ... These values are not provided in resume challenge , but you will encounter in certification test. So like I said, define your goal of this challenge, whether you want to dive deep into the cloud world or not. 2. Career: It does add some values to your resume to help you stand out from other candidates, especially with this cloud project. Q: Any good resources you recommond to prepare for the exam? A: I used the Dojo bundle along with their exam. This was the only resource I used to prepare for the exam. You are absolutely free to explore any other lessons. (Note: I do not receive any compensation from Dojo and have no personal affiliation with them. I recommend it simply because it was the only resource I used; I cannot guarantee the quality of other materials). *Impotant* Don't pay full price for the certification exam! Look for coupons or vouchers online! 2. Getting Started with AWS and IAM role Head over to AWS and register an account. Yes, you‚Äôll need to enter your credit card info, but don‚Äôt panic, AWS has a free plan that lasts for a year.\nAs for the IAM role, I recommend just sticking with the root user for now. It gives you full access to all the services, otherwise you‚Äôll be tired with a lot of access denials later on.\nWarning: This is a bad practice for security reasons. Don't do this long term! Especially if you're setting this up in a real production environment! 3. HTML \u0026 CSS The foundation of building a website‚Äôs frontend: How you code it depends on your own style and taste. I use Hugo along with its Papermod theme to build my website. I strongly recommend using an existing tool to build your portfolio instead of hand-coding everything with plain HTML and CSS. Here‚Äôs why:\nIf you‚Äôre just starting out and don‚Äôt plan on becoming a frontend developer, it‚Äôs really not the best use of your time. Let‚Äôs be real, writing perfect CSS for a beautifully designed website is super hard, especially when you‚Äôre still learning. Even if you manage to finish your website and the design meets your expectations, consider whether the time spent was worth the result you achieved. Some other popular tools: Adobe, Notion, Wix\nI‚Äôm definitely not trying to discourage anyone from writing their own HTML and CSS. In fact, I absolutely take my hat off for anyone who practice writing good CSS code. My point is just a friendly heads-up. I personally spent over 30 hours coding my site from scratch, and honestly, it still didn‚Äôt come close to what Hugo gave me in way less time. Switching to Hugo was a game changer.\nI came across an HTML \u0026 CSS Tutorial that I found really interesting. Just to clarify, I didn‚Äôt use this tutorial in my own learning journey, but I thought the course designer‚Äôs final task of building a YouTube-style webpage was pretty cool.\n4. Static Website We store the HTML \u0026 CSS files on S3 bucket. Here‚Äôs how you can do it:\nLog in to your AWS S3 console. Click on ‚ÄúCreate bucket‚Äù (it‚Äôs in an orange box). Enter a unique bucket name. This name has to be unique across all AWS accounts in globe. Then, hit ‚ÄúCreate bucket‚Äù. [You don‚Äôt need to change any other settings.] Go to your newly created bucket, click Upload, and upload your files. Make sure that your index.html file is right in the root directory of the bucket. This means when you click on your bucket, you should see index.html directly in the file section, not inside any folder! For future convinience, use AWS CLI to upload the files by terminal. A useful tutorial video from Frank if you need\nCommands we oftenly use:\n// This command updates new file and delete the files that are not presented in the new updated repository. aws s3 sync ./your_folder/ s3://your-bucket --delete --exclude \"*.DS_Store\" --exclude \".gitignore\" --exclude \".git/*\" // Clean up all files in your bucket aws aws s3 rm s3://your-bucket --recursive 5. HTTPS Using HTTPS with CloudFront has several benefits:\nEncryption: HTTPS encrypts your content while it‚Äôs being transferred between AWS and the user‚Äôs PC, keeping it secure. Traffic Control: CloudFront helps manage traffic more efficiently and scales with demand. (Distribution got its name for a reason :) Cost: Serving S3 content via CloudFront is FREE. (Just a note: if you‚Äôre hosting your website via S3, AWS does charge for read times.) Let me break down the CloudFront setup for you:\nLog in to your AWS CloudFront console. Click on ‚ÄúCreate distribution‚Äù (it‚Äôs in an orange box). Update the following sections: Origin domain: Choose the bucket you created. Origin access: Set this to Origin access control settings to ensure that only your distribution can access the S3 content. Click Create New OAC, then Create. Viewer Protocol policy: Select Redirect HTTP to HTTPS. WAF: Do Not Enable Default root object:Only change this if your index.html is named something different, like ‚Äúproject1.html‚Äù or ‚Äúrandom_name.html‚Äù. CloudFront needs to know the name of the root object to serve your content correctly. After creating your distribution, wait about 3-5 minutes for it to deploy. Once it‚Äôs ready, go to your new distribution details. You‚Äôll find a section prompting you to create a policy and paste it into S3. Go to S3 -\u003e Permission in the navbar -\u003e Scroll down to Bucket Policy -\u003e Paste your policy there. If you need a policy template, here‚Äôs one you can use:\n{ \"Version\": \"2008-10-17\", \"Id\": \"PolicyForCloudFrontPrivateContent\", \"Statement\": [ { \"Sid\": \"AllowCloudFrontServicePrincipal\", \"Effect\": \"Allow\", \"Principal\": { \"Service\": \"cloudfront.amazonaws.com\" }, \"Action\": \"s3:GetObject\", \"Resource\": \"arn:aws:s3:::your_bucket/*\", \"Condition\": { \"StringEquals\": { \"AWS:SourceArn\": \"your_cloudfront_arn\" } }, }, ], } Find your ARN Until now, you should be able to see your site from CloudFront URL (Distribution domain name in The above picture) 6. DNS You can buy a domain from anywhere. Some popular options are Route S3, Cloudflare, or any other DNS provider.\nA domain typically costs around $10 a year, and that‚Äôs the only real expense for this project. Refer to your DNS provider for a simple guide on purchasing the domain, it‚Äôs usually just a simple process of typing the desired domain name, paying, and you‚Äôre good to go. Now, let‚Äôs move on to connecting your domain with CloudFront so your S3 content can be accessed through your domain (just like how my site is at https://www.ziirui-resume-website.com). We‚Äôll also use AWS Certificate Manager to add SSL for security.\nSteps for Creating SSL and Verifying Your Domain Log in to the Certificate Manager Console CLick Request (orange button) and then Next Enter your domain name (ex: example.com), then hit Request You‚Äôve now created an SSL certificate, but we need to verify that the domain is yours. Here‚Äôs how to do that:\nScroll down to the Domains section of your new SSL. You‚Äôll see a CNAME name and a CNAME value. these are like a key and value pair. You‚Äôll need to create a record in your DNS provider for each of them. Don‚Äôt panic! Just search ‚Äúadd record in [Your_DNS_provider_name]‚Äù on your browser for step-by-step videos online. Reminder:\nThe record type is CNMAE. The record name is CNAME name. Record target is the CNAME value. Record status is No Proxy. The Do this step for all of your SSL domains. Once you‚Äôve added those records, check back in the Certificate Manager. If everything‚Äôs set up correctly, you‚Äôll see ‚ÄúSuccess.‚Äù After verification, we have proved the DNS ownership to Certificate Manager, now we can connect DNS with our CloudFront. Step below:\nCopy your CloudFront URL Go to your DNS provider and create two CNAME records: One with Name = www and Target = CloudFront URL. Another with Name = your root domain (e.g., example.com) and Target = CloudFront URL. Final look for DNS provider console:\nSetting SSL in CloudFront (Don't panic! It's simple, you've done most of the job): Go to your CloudFront distribution Under General, click Edit Settings. In Alternate domain name (CNAME), enter your domain (‚Äúyour_root_domain‚Äù and ‚Äúwww.your_root_domain‚Äù) In Custom SSL certificate, Select your SSL. Under Custom SSL certificate, select the SSL certificate you created. Now, test your website using your domain. If all went well, your content should be accessible via your personal DNS!\n7. Database For this part, we‚Äôll be using DynamoDB to keep track of our visitor count.\nHere‚Äôs how to create a DynamoDB table:\nSame as always, open your DynamoDB console Click the Create Table (it‚Äôs orange). Fill out the form: Table Name: You can choose any name you like. Partition Key: Enter id and select String Table Setting: Choose Customize settings Read/write capacity settings: Set this to On-demand instead of Provisioned to avoid extra charges. Click Create Table Explanation: The partition key can be anything; it‚Äôs just a way to retrieve the visitor counter from Python later on. We choose On-demand for the table settings to only pay for what we use, rather than the default Provisioned setting which can lead to charge overhead.\nOnce your table is created, click Explore items (found in the orange box at the top right). Scroll down and hit the Create item button. For the id value section, you can enter 1 for simplicity. In the top right corner, click Add new attribute and select Number for the attribute type. This will be used for the visitor count. Create an attribute named count and set its value to 1. Here‚Äôs what it should look like: Now you have an item with an id of 1 and a count value of 1. Next, we‚Äôll set up a Lambda Function to retrieve and increment this value.\n8. Lambda API \u0026 Python Setting up a Lambda Fucntion should be pretty straightforward for you. Just a quick tip: make sure to choose the programming language (the Runtime) you prefer for interacting with the database. For this guide, we‚Äôll use Python. Remember, this Lambda function will trigger every time someone visits your domain.\nWe‚Äôll be using the Boto3 library for working with DynamoDB in Python. Without further word, here‚Äôs a complete code template for your Lambda function:\nWarning: Don‚Äôt copy this code if you‚Äôre not familiar with Python or the Boto3 library. Doing so without understanding could lead to issues and will only cause you more trouble in the long run. import json import boto3 #connect to table dynamodb = boto3.resource(\"dynamodb\") table_name = \"your_table_name\" table = dynamodb.Table(table_name) def lambda_handler(event, context): id = \"your_id\" response = table.get_item(Key={ 'id':id }) # If the item exists, increment the count by 1 if \"Item\" in response: views = response[\"Item\"][\"your_number_type_key_name\"] views += 1 table.put_item(Item = { \"id\" : id, \"your_number_type_key_name\" : views }) # If the item doesn‚Äôt exist,indicating this is the 1st time our site being visited, then create a view of 1 else: views = 1 table.put_item(Item = { \"id\" : id, \"your_number_type_key_name\" : views }) # The content our javascript will receive in html file. return_format = { 'statusCode': 200, 'body': json.dumps({ 'message': 'success', 'count': int(views), 'event': event }) } return return_format After we set up this Python code, you can test your Lambda Function in the AWS console. It should work fine for retrieving DynamoDB data. Now, we need to set up a URL for Lambda so that our local HTML file can trigger this Lambda function.\nSteps to set up the URL: Watch this video for a step-by-step guide.\nNoticeable changes to make:\nAllow Origins: Add your domain values here, such as https://example.com and https://www.example.com Allow headers: Add the value content-type Allow methods: Add POST Max age: Set this to 43200 seconds, which equals 12 hours for caching. Allow credentials: Enable this option to reduce verification times. Click Create Function, and the Function URL should appear at the bottom right corner of your screen. Note: This is a basic setup for convenience, as Function URLs do not address DDoS protection. Two alternative solutions are: 1) Switch to API Gateway for a more web-friendly and secure access method, allowing your website to make requests while restricting access from unauthorized users. 2) Configure the IAM role in Lambda URLs to only allow CORS (your domain) to use the link. 8. Javascript Now that we‚Äôve got the Lambda function reading data from DynamoDB, the next step is getting that data into our HTML file so we can display it on the website. This is where JavaScript comes in handy!\nWe‚Äôll be using a simple format from AWS to help us fetch and display the DynamoDB values.\n(Here is a Javascript tutorial if you need.)\n// Be sure to attch this id in your HTML, (e.g. times\n) const counter = document.querySelector(\".your_counter_id_in_html\"); async function update_views() { try { const response = await fetch(\"your_lambda_function_URL\", { method: \"POST\", // Set the method to POST headers: { \"Content-Type\": \"application/json/update_counter\", }, body: JSON.stringify({}), }); const data = await response.json(); counter.innerHTML = `${data.count}`; } catch (error) { counter.innerHTML = `43`; } } update_views(); Congraduation! You‚Äôve done the webiste part of this challenge. For the rest content is where we dive into the cloud world on CI/CD and Infrastructure as code. So if you inspire to be a cloud engineer, like to challenge yourself\n9. CI/CD Here‚Äôs how we‚Äôll use Github Action. If you‚Äôre not familiar with CI/CD (Continuous Integration and Continuous Deployment), let me give you a quick scenario:\nImagine you push your files to GitHub, but you need those files to be updated on AWS. Without CI/CD, you‚Äôd have to manually update them on AWS, uploading HTML and CSS files to an S3 bucket, updating your Python code in a Lambda function, and possibly adjusting policies in different places. And if a bug pops up after all that work, guess what? You‚Äôd have to go through the whole process again!\nCI/CD automates these tasks, so you don‚Äôt have to handle all that manual work every time you make a change. In our final result, all you need to do is push your code to GitHub using git push origin main, and GitHub will automatically update the changes on AWS for you.\nSteps to create CI/CD pipeline in github action:\nIn your local repository, create a workflow file called front-end-cicd.yml in the .github/workflows directory. If you don‚Äôt have the ‚Äú.github‚Äù and ‚Äúworkflows‚Äù folders, create them manually. You should end up with .github/workflows/front-end-cicd.yml in your repository. Now we‚Äôre writing in YAML. I‚Äôll provide you with two templates for your choice: Github OIDC (Recommonded, safe and prevent key leakage) Jakejarvis‚Äôs CI/CD (Not Recommonded for secure reason, but it‚Äôs generally easy to set up) Option 1: Github OIDC The key difference between OIDC and Jakejarviss‚Äôs CI/CD is that OIDC doesn‚Äôt require your AWS Access Key. Instead, it uses a trusted third-party identity provider for authentication. For example, you can use your Google, GitHub, Facebook, or LinkedIn account to sign in to LeetCode. All these third-party companies are trusted by LeetCode.\nWhen we use GitHub OIDC, GitHub can automatically access your AWS resources based on your GitHub identity, without requiring any AWS keys. This is more secure and convenient.\nSteps to set up OIDC in AWS:\nSet up an identity provider in AWS for GitHub. After creating the OIDC provider, go to the provider and select Assign Role from the top right corner. Select Creating a New Role Modify the following fields, then click Next: Trusted entity type: Web Identity Audience: Select sts.amazonaws.com GitHub organization: Enter your GitHub account name, for example, my name is zirui2333 For the policy, select AdministratorAccess for simplicity, then click Next. Enter a role name of your choice: github_oidc, then click Create Role. Go back to the OIDC provider and select Endpoint verification. Click Manage in Thumbprints and add the hex 1b511abead59c6ce207077c0bf0e0043b1382612 (This might change every year, check online ‚ÄúGithub Thumbprints + current year‚Äù), then click Save changes. Steps to set up a CI/CD YAML file in GitHub:\nCopy the following template into your YAML file:\n# Sample workflow to access AWS resources when workflow is tied to branch # The workflow Creates static website using aws s3 name: AWS Frontend on: push: paths: - \"Your_html_folder/**\" # Trigger CI/CD on changes in your HTML folder branches: \"main\" env: BUCKET_NAME: ${{ secrets.AWS_S3_BUCKET }} AWS_REGION: \"us-east-1\" # permission can be added at job level or workflow level permissions: id-token: write # This is required for requesting the JWT contents: read # This is required for actions/checkout jobs: #Upload frontend code S3PackageUpload: runs-on: ubuntu-latest steps: - name: Git clone the repository uses: actions/checkout@v4 - name: configure aws credentials uses: aws-actions/configure-aws-credentials@v3 with: role-to-assume: \"github-cicd\" # Or replace to the name you set up for iam role role-session-name: aws_frontend_workflow aws-region: ${{ env.AWS_REGION }} # Upload a file to AWS s3 - name: Copy Actual_Resume_Web to s3 run: aws s3 sync ./Your_html_folder/ s3://${{ env.BUCKET_NAME }}/ --delete --exclude \"*.DS_Store\" --exclude \".gitignore\" --exclude \".git/*\" Remember to add Secrets for your S3 bucket name and other credentials.\nOnce you‚Äôve added the secret and modified the template, push the file to GitHub using the following commands:\ngit add .github/workflows/front-end-cicd.yml git commit -m \"Create CI/CD pipeline for frontend\" git push origin main Option 2: Jakejarvis‚Äôs CI/CD Copy the jakejarvis‚Äôs CI/CD template into your YAML file, and replace the top part with:\non: push: paths: - \"Your_html_folder/**\" # This line indicates that CI/CD will only happen if git push contains any files on html folder, in other words, CI/CD will trigger only if there's any change in your frontend code branches: \"main\" Make your S3 bucket publicly readable. Ensure your S3 bucket settings are also configured for public access.\nAdd Secrets to GitHub:\nFollow the steps for adding Secrets, including your S3 bucket name and Access Key ID. I previously shared a video from Frank explaining how to create an access key. You can revisit that here if needed. If you‚Äôve created the access key but can‚Äôt view it again due to AWS‚Äôs security policies, you can retrieve it from your terminal by running: cd ~ # Go to root cat .aws/credentials # Print the access key and id After locating your keys, add them to your GitHub Secrets. Important: Please comment out the SOURCE_DIR: ‚Äòpublic‚Äô line in the Jakejarvis template to prevent conflicts in your system.\nOnce you have modified the template and added your Secrets, push the file to GitHub with:\ngit add .github/workflows/front-end-cicd.yml git commit -m \"Create CI/CD pipeline for frontend\" git push origin main 10. Infrastructure as code This is another essential skill in cloud computing world. We will use Terraform.\nFor the people who doesn‚Äôt know Infrastructure as code, it‚Äôs used for cloud service Automation, in our case is AWS services like S3 bucket, dynamoDB, cloudFront distribution, SSL manager and more‚Ä¶. Let me give you a scenario: Imagine you went through all the steps I listed previously, you saw lots of screenshot configuration from AWS console right? They‚Äôre one of the ways how you can create services in AWS, but imagine soemthing goes wrong, and you need to re-create all the services again (Oh No)! You defintealy don‚Äôt want to manually went over every single service creation again. Therefore here comes the Infrastructure as code, in simple word, we will write codes for those services, sepecifically their configuratioins. So that next time if you want to recreate a series of services, you can just run the code, and it will automatically create everything for you! Sounds amazing right? Let‚Äôs get started!\nSteps for terraform configuaration:\nIf you‚Äôre using VScode, go ahead with this link . If you‚Äôre using other compiler, search ‚ÄúTerraform Installation‚Äù + ‚ÄúYour compilor name‚Äù for guideline Once installation finish, go to your root repo and create a folder named infra. Inside it, create two files main.tf and provider.tf. So their paths should be infra/main.tf and infra/provider.tf Note: Infra folder is just a name for you to distinguish other code from infrastructure part, you can name it anything you want. \"main.tf\" and \"provider.tf\" are mandatory, \"provider.tf\" is where to write configuration for Terraform specifically, telling it we're writing code for AWS, the version of Terraform we're gonna use and the region our AWS services to be, blablabla. \"main.tf\" in the other hand is gonna be the massive place we write AWS services configuration. Don't panic, I will show you examples on how to do it! Write provider.tf copy the code: # Specify Terraform works for AWS, the tool and the version of the tool terraform { required_providers { aws = { source = \"hashicorp/aws\" version = \"\u003e= 4.9.0\" } } # All the configuration status will store in this bucket. I will explain the reason for this later. backend \"s3\" { bucket = \"your-terraform-backup-bucket-name\" key = \"terraform.tfstate\" region = \"us-east-1\" } } # Simply the regions provider \"aws\" { alias = \"us_east_1\" region = \"us-east-1\" } Because we specify a bucket to update our Terraform code, go to console to create a bucket or using the command below if you have AWS CLI install.\n# Remember bucket name needs to be globally unique, replace \"your-terraform-backup-bucket-name\" for another name you like aws s3 mb s3://your-terraform-backup-bucket-name --region us-east-1 The reason for backup bucket is that \"terraform.tfstate\" is a file terraform will create to manage our AWS services that have been created. Just like your github will have \".git\" to check new change in your local code that are different from the one on the github. Terraform has this file created locally. However, let I said previously in CI/CD portion, we want implement an automation pipeline that once we push the code the github, github will deal with AWS instead of us dealing with it. So we will make our terraform to After succefully configuring provider.tf, we‚Äôll dive into the boss provider.tf\n11. Test Cypress This section is still in progress, so stay tuned!\nFeel free to check out my other feature in my portfolio!\n","wordCount":"4150","inLanguage":"en-us","image":"https://www.ziirui-resume-website.com/posts/tech/cloud_website/aws_logo.jpg","datePublished":"2024-08-15T00:00:00Z","dateModified":"2024-08-15T00:00:00Z","author":[{"@type":"Person","name":"Zirui"}],"mainEntityOfPage":{"@type":"WebPage","@id":"https://www.ziirui-resume-website.com/posts/tech/cloud_website/"},"publisher":{"@type":"Organization","name":"Zirui's Space","logo":{"@type":"ImageObject","url":"https://www.ziirui-resume-website.com/img/Q.jpg"}}}</script></head><body id=" top"><script>(function(){let e,t=new RegExp("(^| )change-themes=([^;]*)(;|$)");(e=document.cookie.match(t))||((new Date).getHours()>=19||(new Date).getHours()<6?(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark")):(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")))})(),localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://www.ziirui-resume-website.com/ accesskey=h title="Zirui's Space (Alt + H)"><img src=https://www.ziirui-resume-website.com/img/Q.jpg alt=logo aria-label=logo height=35>Zirui's Space</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://www.ziirui-resume-website.com/ title="üè† Home"><span>üè† Home</span></a></li><li><a href=https://www.ziirui-resume-website.com/posts title="üìö Posts"><span>üìö Posts</span></a></li><li><a href=https://www.ziirui-resume-website.com/about title="üôãüèª‚Äç‚ôÇÔ∏è About"><span>üôãüèª‚Äç‚ôÇÔ∏è About</span></a></li><li><a href=https://www.ziirui-resume-website.com/search title="üîç Search (Alt + /)" accesskey=/><span>üîç Search</span></a></li></ul></nav></header><main class="main page"><style>i[id*=post_meta_style]{display:flex;align-items:center;margin:0 0 10px}</style><article class=post-single><div id=single-content><header class=post-header><div class=breadcrumbs><a href=https://www.ziirui-resume-website.com/>üè† Home</a>&nbsp;¬ª&nbsp;<a href=https://www.ziirui-resume-website.com/posts/>üìöPosts</a>&nbsp;¬ª&nbsp;<a href=https://www.ziirui-resume-website.com/posts/tech/>üë®üèª‚Äçüíª Tech</a></div><h1 class=post-title>Tutorial - An Entry DevOps project</h1><div class=post-description>A comprehensive guide on hosting AWS website along with CI/CD automation and infrastructure as code...</div><div class=post-meta><style>i[id*=post_meta_style]{display:flex;align-items:center;margin:0 0 10px}.parent-post-meta{display:flex;flex-wrap:wrap;opacity:.8}</style><span class=parent-post-meta><span id=post_meta_style_1><span class="fa fa-calendar-check-o"></span>
<span>2024-08-15
&nbsp;&nbsp;
</span></span><span id=post_meta_style_3><span class="fa fa-file-word-o"></span>
<span>4150Â≠ó
&nbsp;&nbsp;
</span></span><span id=post_meta_style_4><span class="fa fa-clock-o"></span>
<span>9ÂàÜÈíü
&nbsp;&nbsp;
</span></span><span id=post_meta_style_5><span class="fa fa-user-o"></span>
<span>Zirui
&nbsp;&nbsp;
</span></span><span id=post_meta_style_6><span class="fa fa-tags" style=opacity:.8></span>
<span><span class=post-tags-meta><a href=https://www.ziirui-resume-website.com/tags/cloud/ style=color:var(--secondary)!important>Cloud</a>
</span></span></span></span><span style=opacity:.8><span id=post_meta_style_7>&nbsp;&nbsp;
<span class="fa fa-eye"></span>
<span><span id=busuanzi_container_page_pv><span id=busuanzi_value_page_pv></span></span>
&nbsp;&nbsp;</span></span></span></div></header><figure class=entry-cover1><img style=zoom: loading=lazy srcset="https://www.ziirui-resume-website.com/posts/tech/cloud_website/posts/tech/cloud_website/aws_logo.jpg 290w" sizes="(min-width: 768px) 720px, 100vw" src=https://www.ziirui-resume-website.com/posts/tech/cloud_website/posts/tech/cloud_website/aws_logo.jpg alt width=290 height=174></figure><aside id=toc-container class="toc-container wide"><div class=toc><details open><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><ul><li><a href=#introduction aria-label=Introduction>Introduction</a></li></ul><li><a href=#1-certification aria-label="1. Certification">1. Certification</a><ul><li><a href=#qa aria-label=Q&amp;A>Q&amp;A</a></li></ul></li><li><a href=#2-getting-started-with-aws-and-iam-role aria-label="2. Getting Started with AWS and IAM role">2. Getting Started with AWS and IAM role</a></li><li><a href=#3-html--css aria-label="3. HTML & CSS">3. HTML & CSS</a></li><li><a href=#4-static-website aria-label="4. Static Website">4. Static Website</a></li><li><a href=#5-https aria-label="5. HTTPS">5. HTTPS</a></li><li><a href=#6-dns aria-label="6. DNS">6. DNS</a></li><li><a href=#7-database aria-label="7. Database">7. Database</a></li><li><a href=#8-lambda-api--python aria-label="8. Lambda API & Python">8. Lambda API & Python</a></li><li><a href=#8-javascript aria-label="8. Javascript">8. Javascript</a></li><li><a href=#9-cicd aria-label="9. CI/CD">9. CI/CD</a><ul><ul><li><a href=#option-1-github-oidc aria-label="Option 1: Github OIDC">Option 1: Github OIDC</a></li><li><a href=#option-2-jakejarviss-cicd aria-label="Option 2: Jakejarvis‚Äôs CI/CD">Option 2: Jakejarvis‚Äôs CI/CD</a></li></ul></ul></li><li><a href=#10-infrastructure-as-code aria-label="10. Infrastructure as code">10. Infrastructure as code</a><ul><li><a href=#write-providertf aria-label="Write provider.tf">Write provider.tf</a></li></ul></li><li><a href=#11-test-cypress aria-label="11. Test Cypress">11. Test Cypress</a></li></ul></div></details></div></aside><script>let activeElement,elements;window.addEventListener("DOMContentLoaded",function(){checkTocPosition(),elements=document.querySelectorAll("h1[id],h2[id],h3[id],h4[id],h5[id],h6[id]"),activeElement=elements[0];const t=encodeURI(activeElement.getAttribute("id")).toLowerCase();document.querySelector(`.inner ul li a[href="#${t}"]`).classList.add("active")},!1),window.addEventListener("resize",function(){checkTocPosition()},!1),window.addEventListener("scroll",()=>{elements&&(activeElement=Array.from(elements).find(e=>{if(getOffsetTop(e)-window.pageYOffset>0&&getOffsetTop(e)-window.pageYOffset<window.innerHeight/2)return e})||activeElement,elements.forEach(e=>{const t=encodeURI(e.getAttribute("id")).toLowerCase();e===activeElement?document.querySelector(`.inner ul li a[href="#${t}"]`).classList.add("active"):document.querySelector(`.inner ul li a[href="#${t}"]`).classList.remove("active")}))},!1);const main=parseInt(getComputedStyle(document.body).getPropertyValue("--article-width"),10),toc=parseInt(getComputedStyle(document.body).getPropertyValue("--toc-width"),10),gap=parseInt(getComputedStyle(document.body).getPropertyValue("--gap"),10);function checkTocPosition(){const e=document.body.scrollWidth;e-main-toc*2-gap*4>0?document.getElementById("toc-container").classList.add("wide"):document.getElementById("toc-container").classList.remove("wide")}function getOffsetTop(e){if(!e.getClientRects().length)return 0;let t=e.getBoundingClientRect(),n=e.ownerDocument.defaultView;return t.top+n.pageYOffset}</script><div class=post-content><style>.post-content img{max-width:750px;height:auto}</style><h2 id=introduction>Introduction<a hidden class=anchor aria-hidden=true href=#introduction>#</a></h2><p>This guide is based on the <a href=https://cloudresumechallenge.dev/docs/the-challenge/aws/ target=_blank>Cloud Resume Challenge</a> and follows the steps listed inside it. That said, I strongly recommend purchasing the original book as it covers much more details. This post will only show the method I&rsquo;ve done for my challenge. Think of this post as a helpful guide rather than a complete answer key.</p><p>The elements cover in this post:</p><ol><li><strong>AWS</strong> (S3 bucket, Cloudfront, IAM, Lambda Function, DynamoDB, Identity Provider OIDC, DNS, SSL Manager and more)</li><li><strong>CI/CD</strong> (Git Action)</li><li><strong>infrastructure as code</strong> (Terraform)</li><li><strong>Frontend Language</strong> (HTML, CSS) -> Now switch to Hugo</li><li><strong>Backend Language</strong> (Python, Javascript)</li><li><strong>Test</strong> (Cypress)</li></ol><div class=highlight><pre tabindex=0 class=chroma><code class=language-yaml data-lang=yaml><span class=line><span class=cl><span class=l>Please read through the &lt;challenge&gt; on the offical website before looking into my post, because I will directly dive into how I solve the problem.</span><span class=w>
</span></span></span></code></pre></div><h1 id=1-certification>1. Certification<a hidden class=anchor aria-hidden=true href=#1-certification>#</a></h1><p>The challenge recommonds the <a href=https://aws.amazon.com/certification/certified-cloud-practitioner/ target=_blank>Certified Cloud Practitioner</a> as a basic level. However I passed the <a href=https://aws.amazon.com/certification/certified-solutions-architect-associate/ target=_blank>Solutions Architect - Associate</a> for a higher level approach. Ultimately the certificate offers professional knowledge regarding cloud services.</p><h2 id=qa>Q&amp;A<a hidden class=anchor aria-hidden=true href=#qa>#</a></h2><ul><li>Q: Is getting a certificate worthy?</li><li>A: The short answer: yes and no. If you want to become a cloud engineer or similar role (Site reliabilty Engineer, DevOps engineer), the answer is yes! If your goal is just to learn cloud services, then a certificate will not be worthy. Here are 2 major benefits:</li></ul><div class=highlight><pre tabindex=0 class=chroma><code class=language-yaml data-lang=yaml><span class=line><span class=cl><span class=nt>1. Experience from the Certificate</span><span class=p>:</span><span class=w> </span><span class=l>The resume challenge will guide you through a limited set of AWS resources, specifically focusing on how to host a static website. Most of the time, you will need to handle various scenarios.</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>Let me offer you some cases</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>   </span>- <span class=l>Are you familiar with VPC networks and EC2 instances, which are commonly used by companies?</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>   </span>- <span class=l>How to prevent accidental deletion in bucket? (Versioning / MFA)</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>   </span>- <span class=l>Do you understand the architectural difference between a company that wants to migrate services from on-premise to the cloud while treating the on-premise data center as a backup, versus a company that wants to extend its data storage to the cloud but keep all services hosted on-premises?</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>   </span>- <span class=l>...</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=l>These values are not provided in resume challenge , but you will encounter in certification test. So like I said, define your goal of this challenge, whether you want to dive deep into the cloud world or not.</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>2. Career</span><span class=p>:</span><span class=w> </span><span class=l>It does add some values to your resume to help you stand out from other candidates, especially with this cloud project.</span><span class=w>
</span></span></span></code></pre></div><br><ul><li>Q: Any good resources you recommond to prepare for the exam?</li><li>A: I used the <a href=https://portal.tutorialsdojo.com/video-course-practice-test/ target=_blank>Dojo bundle</a> along with their exam. This was the only resource I used to prepare for the exam. You are absolutely free to explore any other lessons. (Note: I do not receive any compensation from Dojo and have no personal affiliation with them. I recommend it simply because it was the only resource I used; I cannot guarantee the quality of other materials).</li></ul><div class=highlight><pre tabindex=0 class=chroma><code class=language-yaml data-lang=yaml><span class=line><span class=cl><span class=cp>*Impotant*</span><span class=w> </span><span class=l>Don&#39;t pay full price for the certification exam! Look for coupons or vouchers online!</span><span class=w>
</span></span></span></code></pre></div><h1 id=2-getting-started-with-aws-and-iam-role>2. Getting Started with AWS and IAM role<a hidden class=anchor aria-hidden=true href=#2-getting-started-with-aws-and-iam-role>#</a></h1><p>Head over to <a href="https://aws.amazon.com/free/?gclid=CjwKCAjwxY-3BhAuEiwAu7Y6s5OVtdXjaHVkG9k79n5iiGcp5FbbmCkHe4FTIk8G1MRq8nIFz-8R4hoCgNoQAvD_BwE&trk=fce796e8-4ceb-48e0-9767-89f7873fac3d&sc_channel=ps&ef_id=CjwKCAjwxY-3BhAuEiwAu7Y6s5OVtdXjaHVkG9k79n5iiGcp5FbbmCkHe4FTIk8G1MRq8nIFz-8R4hoCgNoQAvD_BwE:G:s&s_kwcid=AL!4422!3!432339156150!e!!g!!aws!1644045032!68366401852&all-free-tier.sort-by=item.additionalFields.SortRank&all-free-tier.sort-order=asc&awsf.Free%20Tier%20Types=*all&awsf.Free%20Tier%20Categories=*all" target=_blank>AWS</a> and register an account. Yes, you‚Äôll need to enter your credit card info, but don‚Äôt panic, AWS has a free plan that lasts for a year.</p><p>As for the IAM role, I recommend just sticking with the root user for now. It gives you full access to all the services, otherwise you&rsquo;ll be tired with a lot of access denials later on.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-yaml data-lang=yaml><span class=line><span class=cl><span class=nt>Warning</span><span class=p>:</span><span class=w> </span><span class=l>This is a bad practice for security reasons. Don&#39;t do this long term! Especially if you&#39;re setting this up in a real production environment!</span><span class=w>
</span></span></span></code></pre></div><h1 id=3-html--css>3. HTML & CSS<a hidden class=anchor aria-hidden=true href=#3-html--css>#</a></h1><p>The foundation of building a website&rsquo;s frontend:
How you code it depends on your own style and taste. I use <a href=https://gohugo.io/ target=_blank>Hugo</a> along with its <a href=https://github.com/adityatelange/hugo-PaperMod target=_blank>Papermod</a> theme to build my website. I <strong>strongly recommend</strong> using an existing tool to build your portfolio instead of hand-coding everything with plain HTML and CSS. Here‚Äôs why:</p><ol><li>If you&rsquo;re just starting out and don&rsquo;t plan on becoming a frontend developer, it&rsquo;s really not the best use of your time.</li><li>Let‚Äôs be real, writing perfect CSS for a beautifully designed website is super hard, especially when you&rsquo;re still learning.</li><li>Even if you manage to finish your website and the design meets your expectations, consider whether the time spent was worth the result you achieved.</li></ol><p>Some other popular tools: <a href=https://www.adobe.com/express/create/online-portfolio target=_blank>Adobe</a>, <a href=https://www.notion.so/templates/category/portfolio target=_blank>Notion</a>, <a href=https://www.wix.com/ target=_blank>Wix</a></p><p>I&rsquo;m definitely not trying to discourage anyone from writing their own HTML and CSS. In fact, I absolutely take my hat off for anyone who practice writing good CSS code. My point is just a friendly heads-up. I personally spent over 30 hours coding my site from scratch, and honestly, it still didn‚Äôt come close to what Hugo gave me in way less time. Switching to Hugo was a game changer.</p><p>I came across an <a href="https://www.youtube.com/watch?v=G3e-cpL7ofc&ab_channel=SuperSimpleDev" target=_blank>HTML & CSS Tutorial</a> that I found really interesting. Just to clarify, I didn‚Äôt use this tutorial in my own learning journey, but I thought the course designer‚Äôs final task of building a YouTube-style webpage was pretty cool.</p><h1 id=4-static-website>4. Static Website<a hidden class=anchor aria-hidden=true href=#4-static-website>#</a></h1><p>We store the HTML & CSS files on S3 bucket. Here&rsquo;s how you can do it:</p><ol><li>Log in to your <a href="https://us-east-1.console.aws.amazon.com/s3/home?region=us-east-1#" target=_blank>AWS S3 console</a>.</li><li>Click on <strong>&ldquo;Create bucket&rdquo;</strong> (it&rsquo;s in an orange box).</li><li>Enter a unique <code>bucket name</code>. This name has to be unique across all AWS accounts in globe. Then, hit &ldquo;Create bucket&rdquo;. [You don‚Äôt need to change any other settings.]
<img loading=lazy src=posts/tech/cloud_website/create_bucket.png alt="Create Bucket"></li><li>Go to your newly created bucket, click <strong>Upload</strong>, and upload your files. <strong>Make sure that your index.html file is right in the root directory of the bucket</strong>. This means when you click on your bucket, you should see index.html directly in the file section, not inside any folder!</li></ol><p>For future convinience, use <a href=https://docs.aws.amazon.com/cli/latest/userguide/getting-started-install.html target=_blank>AWS CLI</a> to upload the files by terminal. A useful <a href="https://www.youtube.com/watch?v=IZj_2p1_V1E&ab_channel=networkwithfrank" target=_blank>tutorial video from Frank</a> if you need</p><p>Commands we oftenly use:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>// This <span class=nb>command</span> updates new file and delete the files that are not presented in the new updated repository.
</span></span><span class=line><span class=cl>aws s3 sync ./your_folder/ s3://your-bucket --delete --exclude <span class=s2>&#34;*.DS_Store&#34;</span> --exclude <span class=s2>&#34;.gitignore&#34;</span> --exclude <span class=s2>&#34;.git/*&#34;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>// Clean up all files in your bucket
</span></span><span class=line><span class=cl>aws aws s3 rm s3://your-bucket --recursive
</span></span></code></pre></div><h1 id=5-https>5. HTTPS<a hidden class=anchor aria-hidden=true href=#5-https>#</a></h1><p>Using HTTPS with CloudFront has several benefits:</p><ol><li><strong>Encryption</strong>: HTTPS encrypts your content while it&rsquo;s being transferred between AWS and the user&rsquo;s PC, keeping it secure.</li><li><strong>Traffic Control</strong>: CloudFront helps manage traffic more efficiently and scales with demand. (Distribution got its name for a reason :)</li><li><strong>Cost</strong>: Serving S3 content via CloudFront is <strong>FREE</strong>. (Just a note: if you&rsquo;re hosting your website via <a href=https://docs.aws.amazon.com/AmazonS3/latest/userguide/HostingWebsiteOnS3Setup.html#step2-create-bucket-config-as-website target=_blank>S3</a>, AWS does charge for read times.)</li></ol><p>Let me break down the CloudFront setup for you:</p><ol><li>Log in to your <a href="https://us-east-1.console.aws.amazon.com/cloudfront/v4/home?region=us-east-1#/distributions" target=_blank>AWS CloudFront console</a>.</li><li>Click on <strong>&ldquo;Create distribution&rdquo;</strong> (it&rsquo;s in an orange box).</li><li>Update the following sections:<ul><li><strong>Origin domain</strong>: Choose the bucket you created.</li><li><strong>Origin access</strong>: Set this to <code>Origin access control settings</code> to ensure that only your distribution can access the S3 content.<ul><li>Click <strong>Create New OAC</strong>, then <strong>Create</strong>.</li></ul></li><li><strong>Viewer Protocol policy</strong>: Select <code>Redirect HTTP to HTTPS</code>.</li><li><strong>WAF</strong>: <code>Do Not Enable</code></li><li><strong>Default root object</strong>:Only change this if your <code>index.html</code> is named something different, like &ldquo;project1.html&rdquo; or &ldquo;random_name.html&rdquo;. CloudFront needs to know the name of the root object to serve your content correctly.</li></ul></li><li>After creating your distribution, wait about 3-5 minutes for it to deploy. Once it&rsquo;s ready, go to your new distribution details. You&rsquo;ll find a section prompting you to create a policy and paste it into S3.<ul><li>Go to S3 -> <strong>Permission</strong> in the navbar -> Scroll down to <strong>Bucket Policy</strong> -> Paste your policy there.</li></ul></li></ol><p>If you need a policy template, here&rsquo;s one you can use:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-yaml data-lang=yaml><span class=line><span class=cl>{<span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>&#34;Version&#34;: </span><span class=s2>&#34;2008-10-17&#34;</span><span class=p>,</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>&#34;Id&#34;: </span><span class=s2>&#34;PolicyForCloudFrontPrivateContent&#34;</span><span class=p>,</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=s2>&#34;Statement&#34;</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=p>[</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span>{<span class=w>
</span></span></span><span class=line><span class=cl><span class=w>        </span><span class=nt>&#34;Sid&#34;: </span><span class=s2>&#34;AllowCloudFrontServicePrincipal&#34;</span><span class=p>,</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>        </span><span class=nt>&#34;Effect&#34;: </span><span class=s2>&#34;Allow&#34;</span><span class=p>,</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>        </span><span class=nt>&#34;Principal&#34;: { &#34;Service&#34;: </span><span class=s2>&#34;cloudfront.amazonaws.com&#34;</span><span class=w> </span>}<span class=p>,</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>        </span><span class=nt>&#34;Action&#34;: </span><span class=s2>&#34;s3:GetObject&#34;</span><span class=p>,</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>        </span><span class=nt>&#34;Resource&#34;: </span><span class=s2>&#34;arn:aws:s3:::your_bucket/*&#34;</span><span class=p>,</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>        </span><span class=s2>&#34;Condition&#34;</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>          </span>{<span class=w> </span><span class=nt>&#34;StringEquals&#34;: { &#34;AWS:SourceArn&#34;: </span><span class=s2>&#34;your_cloudfront_arn&#34;</span><span class=w> </span>}<span class=w> </span>}<span class=p>,</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span>}<span class=p>,</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=p>],</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span>}<span class=w>
</span></span></span></code></pre></div><p>Find your ARN
<img loading=lazy src=posts/tech/cloud_website/cloudFront_arn.png alt="ARN For Cloudfront"></p><ol start=5><li>Until now, you should be able to see your site from <code>CloudFront URL</code> (Distribution domain name in The above picture)</li></ol><h1 id=6-dns>6. DNS<a hidden class=anchor aria-hidden=true href=#6-dns>#</a></h1><p>You can buy a domain from anywhere. Some popular options are <a href="https://us-east-1.console.aws.amazon.com/route53/v2/home?region=us-east-1#Home" target=_blank>Route S3</a>, <a href=https://www.cloudflare.com/ target=_blank>Cloudflare</a>, or any other DNS provider.</p><ol><li>A domain typically costs around $10 a year, and that&rsquo;s the only real expense for this project.</li><li>Refer to your DNS provider for a simple guide on purchasing the domain, it‚Äôs usually just a simple process of typing the desired domain name, paying, and you‚Äôre good to go.</li></ol><p>Now, let&rsquo;s move on to connecting your domain with CloudFront so your S3 content can be accessed through your domain (just like how my site is at <a href=https://www.ziirui-resume-website.com>https://www.ziirui-resume-website.com</a>). We‚Äôll also use AWS Certificate Manager to add SSL for security.</p><br>Steps for Creating SSL and Verifying Your Domain<ol><li>Log in to the <a href="https://us-east-1.console.aws.amazon.com/acm/home?region=us-east-1#/certificates/list" target=_blank>Certificate Manager Console</a></li><li>CLick <strong>Request</strong> (orange button) and then <strong>Next</strong></li><li>Enter your domain name (ex: example.com), then hit <strong>Request</strong></li></ol><p>You‚Äôve now created an SSL certificate, but we need to verify that the domain is yours. Here&rsquo;s how to do that:</p><ol start=4><li><p>Scroll down to the <strong>Domains</strong> section of your new SSL. You‚Äôll see a <strong>CNAME name</strong> and a <strong>CNAME value</strong>. these are like a key and value pair. You‚Äôll need to create a record in your DNS provider for each of them. Don&rsquo;t panic! Just search &ldquo;add record in [Your_DNS_provider_name]&rdquo; on your browser for step-by-step videos online. Reminder:</p><ul><li>The record type is <code>CNMAE</code>.</li><li>The record name is <code>CNAME name</code>.</li><li>Record target is the <code>CNAME value</code>.</li><li>Record status is <code>No Proxy</code>.</li></ul></li><li><p>The Do this step for all of your SSL domains. Once you&rsquo;ve added those records, check back in the <a href="https://us-east-1.console.aws.amazon.com/acm/home?region=us-east-1#/certificates/list" target=_blank>Certificate Manager</a>. If everything‚Äôs set up correctly, you‚Äôll see &ldquo;Success.&rdquo;
<img loading=lazy src=posts/tech/cloud_website/Cname_ssl.png alt="Cname success"></p></li><li><p>After verification, we have proved the DNS ownership to Certificate Manager, now we can connect DNS with our CloudFront. Step below:</p><ol><li>Copy your CloudFront URL</li><li>Go to your DNS provider and create two <code>CNAME</code> records:<ul><li>One with Name = <code>www</code> and Target = CloudFront URL.</li><li>Another with Name = your root domain (e.g., example.com) and Target = CloudFront URL.</li></ul></li></ol></li></ol><p>Final look for DNS provider console:</p><p><img loading=lazy src=posts/tech/cloud_website/site_ssl.png alt="Cname result"></p><br>Setting SSL in CloudFront (Don't panic! It's simple, you've done most of the job):<ol><li>Go to your <a href="https://us-east-1.console.aws.amazon.com/cloudfront/v4/home?region=us-east-1#/distributions" target=_blank>CloudFront distribution</a></li><li>Under <strong>General</strong>, click <strong>Edit Settings</strong>.</li><li>In <strong>Alternate domain name (CNAME)</strong>, enter your domain (&ldquo;your_root_domain&rdquo; and &ldquo;www.your_root_domain&rdquo;)</li><li>In <strong>Custom SSL certificate</strong>, Select your SSL.
<img loading=lazy src=posts/tech/cloud_website/SSL_cloudfront.png alt="Cloudfront SSL"></li><li>Under <strong>Custom SSL certificate</strong>, select the SSL certificate you created.</li></ol><p>Now, test your website using your domain. If all went well, your content should be accessible via your personal DNS!</p><h1 id=7-database>7. Database<a hidden class=anchor aria-hidden=true href=#7-database>#</a></h1><p>For this part, we&rsquo;ll be using <a href="https://us-east-1.console.aws.amazon.com/dynamodbv2/home?region=us-east-1#tables" target=_blank>DynamoDB</a> to keep track of our visitor count.</p><p>Here‚Äôs how to create a DynamoDB table:</p><ol><li>Same as always, open your <a href="https://us-east-1.console.aws.amazon.com/dynamodbv2/home?region=us-east-1#tables" target=_blank>DynamoDB console</a></li><li>Click the <strong>Create Table</strong> (it&rsquo;s orange).</li><li>Fill out the form:<ul><li><strong>Table Name</strong>: You can choose any name you like.</li><li><strong>Partition Key</strong>: Enter <code>id</code> and select <code>String</code></li><li><strong>Table Setting</strong>: Choose <code>Customize settings</code></li><li><strong>Read/write capacity settings</strong>: Set this to <code>On-demand</code> instead of <code>Provisioned</code> to avoid extra charges.</li></ul></li><li>Click <strong>Create Table</strong></li></ol><p>Explanation: The partition key can be anything; it&rsquo;s just a way to retrieve the <code>visitor counter</code> from Python later on. We choose <code>On-demand</code> for the table settings to only pay for what we use, rather than the default <code>Provisioned</code> setting which can lead to charge overhead.</p><ol start=5><li>Once your table is created, click <strong>Explore items</strong> (found in the orange box at the top right).</li><li>Scroll down and hit the <strong>Create item</strong> button.</li><li>For the <code>id</code> value section, you can enter <code>1</code> for simplicity.</li><li>In the top right corner, click <strong>Add new attribute</strong> and select <code>Number</code> for the attribute type. This will be used for the visitor count.</li><li>Create an attribute named <code>count</code> and set its value to <code>1</code>.</li></ol><p>Here‚Äôs what it should look like:
<img loading=lazy src=posts/tech/cloud_website/dynamodb_table_item.png alt=dynamodb_table_item></p><p>Now you have an item with an <code>id</code> of <code>1</code> and a count value of <code>1</code>. Next, we‚Äôll set up a Lambda Function to retrieve and increment this value.</p><h1 id=8-lambda-api--python>8. Lambda API & Python<a hidden class=anchor aria-hidden=true href=#8-lambda-api--python>#</a></h1><p>Setting up a <a href="https://us-east-1.console.aws.amazon.com/lambda/home?region=us-east-1#/functions" target=_blank>Lambda Fucntion</a> should be pretty straightforward for you. Just a quick tip: make sure to choose the programming language (the <code>Runtime</code>) you prefer for interacting with the database. For this guide, we&rsquo;ll use Python. Remember, this Lambda function will trigger every time someone visits your domain.</p><p>We‚Äôll be using the <a href=https://boto3.amazonaws.com/v1/documentation/api/latest/guide/dynamodb.html target=_blank>Boto3</a> library for working with DynamoDB in Python. Without further word, here‚Äôs a complete code template for your Lambda function:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-yaml data-lang=yaml><span class=line><span class=cl><span class=nt>Warning</span><span class=p>:</span><span class=w> </span><span class=l>Don‚Äôt copy this code if you‚Äôre not familiar with Python or the Boto3 library. Doing so without understanding could lead to issues and will only cause you more trouble in the long run.</span><span class=w>
</span></span></span></code></pre></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-py data-lang=py><span class=line><span class=cl><span class=kn>import</span> <span class=nn>json</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>boto3</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl> <span class=c1>#connect to table</span>
</span></span><span class=line><span class=cl><span class=n>dynamodb</span> <span class=o>=</span> <span class=n>boto3</span><span class=o>.</span><span class=n>resource</span><span class=p>(</span><span class=s2>&#34;dynamodb&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>table_name</span> <span class=o>=</span> <span class=s2>&#34;your_table_name&#34;</span>
</span></span><span class=line><span class=cl><span class=n>table</span> <span class=o>=</span> <span class=n>dynamodb</span><span class=o>.</span><span class=n>Table</span><span class=p>(</span><span class=n>table_name</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>lambda_handler</span><span class=p>(</span><span class=n>event</span><span class=p>,</span> <span class=n>context</span><span class=p>):</span>
</span></span><span class=line><span class=cl>  <span class=nb>id</span> <span class=o>=</span> <span class=s2>&#34;your_id&#34;</span>
</span></span><span class=line><span class=cl>  <span class=n>response</span> <span class=o>=</span> <span class=n>table</span><span class=o>.</span><span class=n>get_item</span><span class=p>(</span><span class=n>Key</span><span class=o>=</span><span class=p>{</span>
</span></span><span class=line><span class=cl>      <span class=s1>&#39;id&#39;</span><span class=p>:</span><span class=nb>id</span>
</span></span><span class=line><span class=cl>  <span class=p>})</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  <span class=c1># If the item exists, increment the count by 1</span>
</span></span><span class=line><span class=cl>  <span class=k>if</span> <span class=s2>&#34;Item&#34;</span> <span class=ow>in</span> <span class=n>response</span><span class=p>:</span>
</span></span><span class=line><span class=cl>      <span class=n>views</span> <span class=o>=</span> <span class=n>response</span><span class=p>[</span><span class=s2>&#34;Item&#34;</span><span class=p>][</span><span class=s2>&#34;your_number_type_key_name&#34;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>      <span class=n>views</span> <span class=o>+=</span> <span class=mi>1</span>
</span></span><span class=line><span class=cl>      <span class=n>table</span><span class=o>.</span><span class=n>put_item</span><span class=p>(</span><span class=n>Item</span> <span class=o>=</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>          <span class=s2>&#34;id&#34;</span> <span class=p>:</span> <span class=nb>id</span><span class=p>,</span>
</span></span><span class=line><span class=cl>          <span class=s2>&#34;your_number_type_key_name&#34;</span> <span class=p>:</span> <span class=n>views</span>
</span></span><span class=line><span class=cl>      <span class=p>})</span>
</span></span><span class=line><span class=cl>  <span class=c1># If the item doesn‚Äôt exist,indicating this is the 1st time our site being visited, then create a view of 1</span>
</span></span><span class=line><span class=cl>  <span class=k>else</span><span class=p>:</span>
</span></span><span class=line><span class=cl>      <span class=n>views</span> <span class=o>=</span> <span class=mi>1</span>
</span></span><span class=line><span class=cl>      <span class=n>table</span><span class=o>.</span><span class=n>put_item</span><span class=p>(</span><span class=n>Item</span> <span class=o>=</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>          <span class=s2>&#34;id&#34;</span> <span class=p>:</span> <span class=nb>id</span><span class=p>,</span>
</span></span><span class=line><span class=cl>          <span class=s2>&#34;your_number_type_key_name&#34;</span> <span class=p>:</span> <span class=n>views</span>
</span></span><span class=line><span class=cl>      <span class=p>})</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  <span class=c1># The content our javascript will receive in html file.</span>
</span></span><span class=line><span class=cl>  <span class=n>return_format</span> <span class=o>=</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>          <span class=s1>&#39;statusCode&#39;</span><span class=p>:</span> <span class=mi>200</span><span class=p>,</span>
</span></span><span class=line><span class=cl>          <span class=s1>&#39;body&#39;</span><span class=p>:</span> <span class=n>json</span><span class=o>.</span><span class=n>dumps</span><span class=p>({</span>
</span></span><span class=line><span class=cl>              <span class=s1>&#39;message&#39;</span><span class=p>:</span> <span class=s1>&#39;success&#39;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>              <span class=s1>&#39;count&#39;</span><span class=p>:</span> <span class=nb>int</span><span class=p>(</span><span class=n>views</span><span class=p>),</span>
</span></span><span class=line><span class=cl>              <span class=s1>&#39;event&#39;</span><span class=p>:</span> <span class=n>event</span>
</span></span><span class=line><span class=cl>          <span class=p>})</span>
</span></span><span class=line><span class=cl>      <span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  <span class=k>return</span> <span class=n>return_format</span>
</span></span></code></pre></div><p>After we set up this Python code, you can <a href=https://docs.aws.amazon.com/lambda/latest/dg/testing-functions.html#invoke-with-event target=_blank>test your Lambda Function</a> in the AWS console. It should work fine for retrieving DynamoDB data. Now, we need to set up a URL for Lambda so that our local HTML file can trigger this Lambda function.</p><p><strong>Steps to set up the URL:</strong> <a href="https://www.youtube.com/watch?v=VCJTPV0vmwk&start=652" target=_blank>Watch this video for a step-by-step guide.</a></p><p><strong>Noticeable changes to make:</strong></p><ol><li><strong>Allow Origins</strong>: Add your domain values here, such as <code>https://example.com</code> and <code>https://www.example.com</code></li><li><strong>Allow headers</strong>: Add the value <code>content-type</code></li><li><strong>Allow methods</strong>: Add <code>POST</code></li><li><strong>Max age</strong>: Set this to <code>43200</code> seconds, which equals 12 hours for caching.</li><li><strong>Allow credentials</strong>: Enable this option to reduce verification times.</li><li>Click <strong>Create Function</strong>, and the Function URL should appear at the bottom right corner of your screen.</li></ol><div class=highlight><pre tabindex=0 class=chroma><code class=language-yaml data-lang=yaml><span class=line><span class=cl><span class=nt>Note</span><span class=p>:</span><span class=w> </span><span class=l>This is a basic setup for convenience, as Function URLs do not address DDoS protection.</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>Two alternative solutions are</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=m>1</span><span class=l>) Switch to API Gateway for a more web-friendly and secure access method, allowing your website to make requests while restricting access from unauthorized users.</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=m>2</span><span class=l>) Configure the IAM role in Lambda URLs to only allow CORS (your domain) to use the link.</span><span class=w>
</span></span></span></code></pre></div><h1 id=8-javascript>8. Javascript<a hidden class=anchor aria-hidden=true href=#8-javascript>#</a></h1><p>Now that we‚Äôve got the Lambda function reading data from DynamoDB, the next step is getting that data into our HTML file so we can display it on the website. This is where JavaScript comes in handy!</p><p>We‚Äôll be using a simple format from <a href=https://docs.aws.amazon.com/waf/latest/developerguide/waf-js-challenge-api-fetch-wrapper.html target=_blank>AWS</a> to help us fetch and display the DynamoDB values.</p><p>(Here is a <a href=https://www.codecademy.com/learn/introduction-to-javascript target=_blank>Javascript tutorial</a> if you need.)</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-js data-lang=js><span class=line><span class=cl><span class=c1>// Be sure to attch this id in your HTML, (e.g. &lt;p class=&#34;your_counter_id_in_html&#34;&gt; times&lt;/p&gt;)
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=kr>const</span> <span class=nx>counter</span> <span class=o>=</span> <span class=nb>document</span><span class=p>.</span><span class=nx>querySelector</span><span class=p>(</span><span class=s2>&#34;.your_counter_id_in_html&#34;</span><span class=p>);</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kr>async</span> <span class=kd>function</span> <span class=nx>update_views</span><span class=p>()</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>  <span class=k>try</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=kr>const</span> <span class=nx>response</span> <span class=o>=</span> <span class=kr>await</span> <span class=nx>fetch</span><span class=p>(</span><span class=s2>&#34;your_lambda_function_URL&#34;</span><span class=p>,</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>      <span class=nx>method</span><span class=o>:</span> <span class=s2>&#34;POST&#34;</span><span class=p>,</span> <span class=c1>// Set the method to POST
</span></span></span><span class=line><span class=cl><span class=c1></span>      <span class=nx>headers</span><span class=o>:</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;Content-Type&#34;</span><span class=o>:</span> <span class=s2>&#34;application/json/update_counter&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>      <span class=p>},</span>
</span></span><span class=line><span class=cl>      <span class=nx>body</span><span class=o>:</span> <span class=nx>JSON</span><span class=p>.</span><span class=nx>stringify</span><span class=p>({}),</span>
</span></span><span class=line><span class=cl>    <span class=p>});</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=kr>const</span> <span class=nx>data</span> <span class=o>=</span> <span class=kr>await</span> <span class=nx>response</span><span class=p>.</span><span class=nx>json</span><span class=p>();</span>
</span></span><span class=line><span class=cl>    <span class=nx>counter</span><span class=p>.</span><span class=nx>innerHTML</span> <span class=o>=</span> <span class=sb>`</span><span class=si>${</span><span class=nx>data</span><span class=p>.</span><span class=nx>count</span><span class=si>}</span><span class=sb>`</span><span class=p>;</span>
</span></span><span class=line><span class=cl>  <span class=p>}</span> <span class=k>catch</span> <span class=p>(</span><span class=nx>error</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=nx>counter</span><span class=p>.</span><span class=nx>innerHTML</span> <span class=o>=</span> <span class=sb>`43`</span><span class=p>;</span>
</span></span><span class=line><span class=cl>  <span class=p>}</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nx>update_views</span><span class=p>();</span>
</span></span></code></pre></div><p>Congraduation! You&rsquo;ve done the webiste part of this challenge. For the rest content is where we dive into the cloud world on CI/CD and Infrastructure as code. So if you inspire to be a cloud engineer, like to challenge yourself</p><h1 id=9-cicd>9. CI/CD<a hidden class=anchor aria-hidden=true href=#9-cicd>#</a></h1><p>Here&rsquo;s how we‚Äôll use <a href=https://docs.github.com/en/actions/writing-workflows/quickstart target=_blank>Github Action</a>. If you&rsquo;re not familiar with CI/CD (Continuous Integration and Continuous Deployment), let me give you a quick scenario:</p><p>Imagine you push your files to GitHub, but you need those files to be updated on AWS. Without CI/CD, you‚Äôd have to manually update them on AWS, uploading HTML and CSS files to an S3 bucket, updating your Python code in a Lambda function, and possibly adjusting policies in different places. And if a bug pops up after all that work, guess what? You‚Äôd have to go through the whole process again!</p><p>CI/CD automates these tasks, so you don&rsquo;t have to handle all that manual work every time you make a change. In our final result, all you need to do is push your code to GitHub using <code>git push origin main</code>, and GitHub will automatically update the changes on AWS for you.</p><br><p><strong>Steps to create CI/CD pipeline in github action:</strong></p><ol><li>In your local repository, create a workflow file called <code>front-end-cicd.yml</code> in the <code>.github/workflows</code> directory. If you don&rsquo;t have the &ldquo;.github&rdquo; and &ldquo;workflows&rdquo; folders, create them manually. You should end up with <code>.github/workflows/front-end-cicd.yml</code> in your repository.</li><li>Now we‚Äôre writing in YAML. I&rsquo;ll provide you with two templates for your choice:</li></ol><ul><li><a href=#option-1-github-oidc>Github OIDC </a>(Recommonded, safe and prevent key leakage)</li><li><a href=#option-2-jakejarviss-cicd>Jakejarvis‚Äôs CI/CD</a> (Not Recommonded for secure reason, but it‚Äôs generally easy to set up)</li></ul><br><h3 id=option-1-github-oidc>Option 1: Github OIDC<a hidden class=anchor aria-hidden=true href=#option-1-github-oidc>#</a></h3><ol><li><p>The key difference between OIDC and Jakejarviss&rsquo;s CI/CD is that OIDC doesn‚Äôt require your AWS Access Key. Instead, it uses a trusted third-party identity provider for authentication. For example, you can use your Google, GitHub, Facebook, or LinkedIn account to sign in to LeetCode. All these third-party companies are trusted by LeetCode.</p></li><li><p>When we use GitHub OIDC, GitHub can automatically access your AWS resources based on your GitHub identity, without requiring any AWS keys. This is more secure and convenient.</p></li></ol><br><p><strong>Steps to set up OIDC in AWS:</strong></p><ol><li>Set up an <a href=https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_providers_create_oidc.html#manage-oidc-provider-console target=_blank>identity provider</a> in AWS for GitHub.</li><li>After creating the OIDC provider, go to the provider and select <strong>Assign Role</strong> from the top right corner.</li><li>Select <code>Creating a New Role</code></li><li>Modify the following fields, then click <strong>Next</strong>:<ul><li><strong>Trusted entity type</strong>: <code>Web Identity</code></li><li><strong>Audience</strong>: Select <code>sts.amazonaws.com</code></li><li><strong>GitHub organization</strong>: Enter your GitHub account name, for example, my name is <code>zirui2333</code></li></ul></li><li>For the <strong>policy</strong>, select <code>AdministratorAccess</code> for simplicity, then click <strong>Next</strong>.</li><li>Enter a role name of your choice: <code>github_oidc</code>, then click <strong>Create Role</strong>.</li><li>Go back to the OIDC provider and select <strong>Endpoint verification</strong>.</li><li>Click <strong>Manage</strong> in Thumbprints and add the hex <code>1b511abead59c6ce207077c0bf0e0043b1382612</code> (This might change every year, check online &ldquo;Github Thumbprints + current year&rdquo;), then click <strong>Save changes</strong>.</li></ol><br><p><strong>Steps to set up a CI/CD YAML file in GitHub:</strong></p><ol><li><p>Copy the following template into your YAML file:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-yaml data-lang=yaml><span class=line><span class=cl><span class=c># Sample workflow to access AWS resources when workflow is tied to branch</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=c># The workflow Creates static website using aws s3</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>AWS Frontend</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>on</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>push</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>paths</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span>- <span class=s2>&#34;Your_html_folder/**&#34;</span><span class=w> </span><span class=c># Trigger CI/CD on changes in your HTML folder</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>branches</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;main&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>env</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>BUCKET_NAME</span><span class=p>:</span><span class=w> </span><span class=l>${{ secrets.AWS_S3_BUCKET }}</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>AWS_REGION</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;us-east-1&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=c># permission can be added at job level or workflow level</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>permissions</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>id-token</span><span class=p>:</span><span class=w> </span><span class=l>write</span><span class=w> </span><span class=c># This is required for requesting the JWT</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>contents</span><span class=p>:</span><span class=w> </span><span class=l>read</span><span class=w> </span><span class=c># This is required for actions/checkout</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>jobs</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=c>#Upload frontend code</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>S3PackageUpload</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>runs-on</span><span class=p>:</span><span class=w> </span><span class=l>ubuntu-latest</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>steps</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span>- <span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>Git clone the repository</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>        </span><span class=nt>uses</span><span class=p>:</span><span class=w> </span><span class=l>actions/checkout@v4</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span>- <span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>configure aws credentials</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>        </span><span class=nt>uses</span><span class=p>:</span><span class=w> </span><span class=l>aws-actions/configure-aws-credentials@v3</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>        </span><span class=nt>with</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>          </span><span class=nt>role-to-assume</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;github-cicd&#34;</span><span class=w> </span><span class=c># Or replace to the name you set up for iam role</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>          </span><span class=nt>role-session-name</span><span class=p>:</span><span class=w> </span><span class=l>aws_frontend_workflow</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>          </span><span class=nt>aws-region</span><span class=p>:</span><span class=w> </span><span class=l>${{ env.AWS_REGION }}</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=c># Upload a file to AWS s3</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span>- <span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>Copy Actual_Resume_Web to s3</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>        </span><span class=nt>run</span><span class=p>:</span><span class=w> </span><span class=l>aws s3 sync ./Your_html_folder/ s3://${{ env.BUCKET_NAME }}/ --delete --exclude &#34;*.DS_Store&#34; --exclude &#34;.gitignore&#34; --exclude &#34;.git/*&#34;</span><span class=w>
</span></span></span></code></pre></div></li><li><p>Remember to <a href=https://docs.github.com/en/actions/security-for-github-actions/security-guides/using-secrets-in-github-actions#creating-secrets-for-a-repository target=_blank>add Secrets</a> for your S3 bucket name and other credentials.</p></li><li><p>Once you‚Äôve added the secret and modified the template, push the file to GitHub using the following commands:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>  git add .github/workflows/front-end-cicd.yml
</span></span><span class=line><span class=cl>  git commit -m <span class=s2>&#34;Create CI/CD pipeline for frontend&#34;</span>
</span></span><span class=line><span class=cl>  git push origin main
</span></span></code></pre></div></li></ol><br><h3 id=option-2-jakejarviss-cicd>Option 2: Jakejarvis‚Äôs CI/CD<a hidden class=anchor aria-hidden=true href=#option-2-jakejarviss-cicd>#</a></h3><ol><li><p>Copy the <a href="https://github.com/jakejarvis/s3-sync-action?tab=readme-ov-file#github-action-to-sync-s3-bucket-" target=_blank>jakejarvis&rsquo;s CI/CD</a> template into your YAML file, and replace the top part with:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-yaml data-lang=yaml><span class=line><span class=cl><span class=nt>on</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>push</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>paths</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span>- <span class=s2>&#34;Your_html_folder/**&#34;</span><span class=w> </span><span class=c># This line indicates that CI/CD will only happen if git push contains any files on html folder, in other words, CI/CD will trigger only if there&#39;s any change in your frontend code</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>branches</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;main&#34;</span><span class=w>
</span></span></span></code></pre></div></li><li><p>Make your S3 bucket publicly readable. Ensure your <a href=https://docs.aws.amazon.com/AmazonS3/latest/userguide/WebsiteAccessPermissionsReqd.html target=_blank>S3 bucket settings</a> are also configured for public access.</p></li><li><p>Add Secrets to GitHub:</p><ul><li>Follow the <a href=https://docs.github.com/en/actions/security-for-github-actions/security-guides/using-secrets-in-github-actions#creating-secrets-for-a-repository target=_blank>steps for adding Secrets</a>, including your S3 bucket name and Access Key ID.</li><li>I previously shared a video from Frank explaining how to create an access key. You can revisit that <a href="https://www.youtube.com/watch?v=IZj_2p1_V1E&ab_channel=networkwithfrank&start=169s" target=_blank>here</a> if needed.</li><li>If you&rsquo;ve created the access key but can&rsquo;t view it again due to AWS&rsquo;s security policies, you can retrieve it from your terminal by running:</li></ul><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>  <span class=nb>cd</span> ~ <span class=c1># Go to root</span>
</span></span><span class=line><span class=cl>  cat .aws/credentials <span class=c1># Print the access key and id</span>
</span></span></code></pre></div></li><li><p>After locating your keys, add them to your GitHub Secrets. Important: Please comment out the SOURCE_DIR: &lsquo;public&rsquo; line in the Jakejarvis template to prevent conflicts in your system.</p></li><li><p>Once you have modified the template and added your Secrets, push the file to GitHub with:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>  git add .github/workflows/front-end-cicd.yml
</span></span><span class=line><span class=cl>  git commit -m <span class=s2>&#34;Create CI/CD pipeline for frontend&#34;</span>
</span></span><span class=line><span class=cl>  git push origin main
</span></span></code></pre></div></li></ol><h1 id=10-infrastructure-as-code>10. Infrastructure as code<a hidden class=anchor aria-hidden=true href=#10-infrastructure-as-code>#</a></h1><p>This is another essential skill in cloud computing world. We will use Terraform.</p><p>For the people who doesn&rsquo;t know <strong>Infrastructure as code</strong>, it&rsquo;s used for cloud service Automation, in our case is AWS services like S3 bucket, dynamoDB, cloudFront distribution, SSL manager and more&mldr;. Let me give you a scenario: Imagine you went through all the steps I listed previously, you saw lots of screenshot configuration from AWS console right? They&rsquo;re one of the ways how you can create services in AWS, but imagine soemthing goes wrong, and you need to re-create all the services again (Oh No)! You defintealy don&rsquo;t want to manually went over every single service creation again. Therefore here comes the <strong>Infrastructure as code</strong>, in simple word, we will write codes for those services, sepecifically their configuratioins. So that next time if you want to recreate a series of services, you can just run the code, and it will automatically create everything for you! Sounds amazing right? Let&rsquo;s get started!</p><p>Steps for terraform configuaration:</p><ol><li>If you&rsquo;re using VScode, go ahead with <a href="https://marketplace.visualstudio.com/items?itemName=HashiCorp.terraform" target=_blank>this link </a>. If you&rsquo;re using other compiler, search &ldquo;Terraform Installation&rdquo; + &ldquo;Your compilor name&rdquo; for guideline</li><li>Once installation finish, go to your root repo and create a folder named <code>infra</code>. Inside it, create two files <code>main.tf</code> and <code>provider.tf</code>. So their paths should be <code>infra/main.tf</code> and <code>infra/provider.tf</code></li></ol><div class=highlight><pre tabindex=0 class=chroma><code class=language-yaml data-lang=yaml><span class=line><span class=cl><span class=nt>Note</span><span class=p>:</span><span class=w> </span><span class=l>Infra folder is just a name for you to distinguish other code from infrastructure part, you can name it anything you want.</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=s2>&#34;main.tf&#34;</span><span class=w> </span><span class=l>and &#34;provider.tf&#34; are mandatory,</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=s2>&#34;provider.tf&#34;</span><span class=w> </span><span class=l>is where to write configuration for Terraform specifically, telling it we&#39;re writing code for AWS, the version of Terraform we&#39;re gonna use and the region our AWS services to be, blablabla.</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=s2>&#34;main.tf&#34;</span><span class=w> </span><span class=l>in the other hand is gonna be the massive place we write AWS services configuration. Don&#39;t panic, I will show you examples on how to do it!</span><span class=w>
</span></span></span></code></pre></div><h2 id=write-providertf>Write provider.tf<a hidden class=anchor aria-hidden=true href=#write-providertf>#</a></h2><ol><li>copy the code:</li></ol><div class=highlight><pre tabindex=0 class=chroma><code class=language-.tf data-lang=.tf><span class=line><span class=cl><span class=c1>  # Specify Terraform works for AWS, the tool and the version of the tool
</span></span></span><span class=line><span class=cl><span class=c1></span>  <span class=nx>terraform</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=nx>required_providers</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>      <span class=na>aws</span> = <span class=p>{</span>
</span></span><span class=line><span class=cl>      <span class=na>source</span>  = <span class=s2>&#34;hashicorp/aws&#34;</span>
</span></span><span class=line><span class=cl>      <span class=na>version</span> = <span class=s2>&#34;&gt;= 4.9.0&#34;</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>  <span class=p>}</span><span class=c1>
</span></span></span><span class=line><span class=cl><span class=c1>
</span></span></span><span class=line><span class=cl><span class=c1>  # All the configuration status will store in this bucket. I will explain the reason for this later.
</span></span></span><span class=line><span class=cl><span class=c1></span>  <span class=nx>backend</span> <span class=s2>&#34;s3&#34;</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=na>bucket</span> = <span class=s2>&#34;your-terraform-backup-bucket-name&#34;</span>
</span></span><span class=line><span class=cl>    <span class=na>key</span>    = <span class=s2>&#34;terraform.tfstate&#34;</span>
</span></span><span class=line><span class=cl>    <span class=na>region</span> = <span class=s2>&#34;us-east-1&#34;</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>  <span class=p>}</span><span class=c1>
</span></span></span><span class=line><span class=cl><span class=c1>
</span></span></span><span class=line><span class=cl><span class=c1>  # Simply the regions
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=kr>  provider</span> <span class=s2>&#34;aws&#34;</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=na>alias</span>  = <span class=s2>&#34;us_east_1&#34;</span>
</span></span><span class=line><span class=cl>    <span class=na>region</span> = <span class=s2>&#34;us-east-1&#34;</span>
</span></span><span class=line><span class=cl>  <span class=p>}</span>
</span></span></code></pre></div><ol start=4><li><p>Because we specify a bucket to update our Terraform code, go to console to create a bucket or using the command below if you have AWS CLI install.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>  <span class=c1># Remember bucket name needs to be globally unique, replace &#34;your-terraform-backup-bucket-name&#34; for another name you like</span>
</span></span><span class=line><span class=cl>  aws s3 mb s3://your-terraform-backup-bucket-name --region us-east-1
</span></span></code></pre></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-yaml data-lang=yaml><span class=line><span class=cl><span class=l>The reason for backup bucket is that &#34;terraform.tfstate&#34; is a file terraform will create to manage our AWS services that have been created. Just like your github will have &#34;.git&#34; to check new change in your local code that are different from the one on the github. Terraform has this file created locally.</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=l>However, let I said previously in CI/CD portion, we want implement an automation pipeline that once we push the code the github, github will deal with AWS instead of us dealing with it. So we will make our terraform to</span><span class=w>
</span></span></span></code></pre></div></li><li><p>After succefully configuring <code>provider.tf</code>, we&rsquo;ll dive into the boss <code>provider.tf</code></p></li></ol><h1 id=11-test-cypress>11. Test Cypress<a hidden class=anchor aria-hidden=true href=#11-test-cypress>#</a></h1><p>This section is still in progress, so stay tuned!</p><p>Feel free to check out my other feature in <a href=https://www.ziirui-resume-website.com target=_blank>my portfolio</a>!</p></div><footer class=post-footer><nav class=paginav><a class=prev href=https://www.ziirui-resume-website.com/posts/tech/matrix_loop/><span class=title>¬´</span><br><span>Struggle with Matrix ClockWise Iteration? Here is all you need to know.</span>
</a><a class=next href=https://www.ziirui-resume-website.com/posts/tech/leetcode_150/><span class=title>¬ª</span><br><span>Leetcode 150</span></a></nav></footer></div></article></main><footer class=footer><span>Copyright
&copy;
2024
<a href=https://www.ziirui-resume-website.com/ style=color:#939393>Zirui's Space</a>
</span><span id=busuanzi_container><span class="fa fa-user"></span> <span id=busuanzi_value_site_uv></span>
<span class="fa fa-eye"></span> <span class=counter_views></span></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><span class=topInner><svg class="topSvg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
<span id=read_progress></span>
</span></a><script>document.addEventListener("scroll",function(){const t=document.getElementById("read_progress"),n=document.documentElement.scrollHeight,s=document.documentElement.clientHeight,o=document.documentElement.scrollTop||document.body.scrollTop;t.innerText=((o/(n-s)).toFixed(2)*100).toFixed(0)})</script><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>let mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>200||document.documentElement.scrollTop>200?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{(function(){document.cookie="change-themes="+escape("false")})(),document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.body.addEventListener("copy",function(e){if(window.getSelection().toString()&&window.getSelection().toString().length>50){let t=e.clipboardData||window.clipboardData;if(t){e.preventDefault();let o="Zirui's Space",n=window.getSelection().toString(),s=window.getSelection().toString();t.setData("text/html",n),t.setData("text/plain",s)}}})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const s=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerText="copy";function i(){t.innerText="copied!",setTimeout(()=>{t.innerText="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){let t=e.textContent;navigator.clipboard.writeText(t),i();return}const n=document.createRange();n.selectNodeContents(e);const s=window.getSelection();s.removeAllRanges(),s.addRange(n);try{document.execCommand("copy"),i()}catch{}s.removeRange(n)});let l=e.className.replaceAll("language-",""),n=document.createElement("div"),a=document.createElement("div"),r=document.createElement("div"),c=document.createElement("div"),o=document.createElement("div");o.innerText=l,n.setAttribute("class","mac-tool"),a.setAttribute("class","mac bb1"),r.setAttribute("class","mac bb2"),c.setAttribute("class","mac bb3"),o.setAttribute("class","language-type"),n.appendChild(a),n.appendChild(r),n.appendChild(c),n.appendChild(o),s.classList.contains("highlight")?(s.appendChild(t),s.appendChild(n)):s.parentNode.firstChild==s||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?(e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t),s.appendChild(n)):(e.parentNode.appendChild(t),s.appendChild(n)))})</script><script>const counter=document.querySelector(".counter_views");async function update_views(){try{const e=await fetch("https://c64v3yvtwepfmc5dd3mskmakn40tpsvk.lambda-url.us-east-1.on.aws/",{method:"POST",headers:{"Content-Type":"application/json/update_counter"},body:JSON.stringify({})}),t=await e.json();counter.innerHTML=`${t.count}`}catch{counter.innerHTML=`570`}}update_views()</script></body></html>